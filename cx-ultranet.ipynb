{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install keras","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:10:50.126954Z","iopub.execute_input":"2022-06-04T04:10:50.127286Z","iopub.status.idle":"2022-06-04T04:10:55.984137Z","shell.execute_reply.started":"2022-06-04T04:10:50.127254Z","shell.execute_reply":"2022-06-04T04:10:55.983362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow import keras\nimport random\nimport cv2\nfrom keras import backend as K\nfrom keras.preprocessing import image\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom tensorflow.compat.v1.logging import INFO, set_verbosity\n\nrandom.seed(a=None, version=2)\n\nset_verbosity(INFO)\n\n\ndef get_mean_std_per_batch(image_path, df, H=320, W=320):\n    sample_data = []\n    for idx, img in enumerate(df.sample(100)[\"Image\"].values):\n        # path = image_dir + img\n        sample_data.append(\n            np.array(image.load_img(image_path, target_size=(H, W))))\n\n    mean = np.mean(sample_data[0])\n    std = np.std(sample_data[0])\n    return mean, std\n\n\ndef load_image(img, image_dir, df, preprocess=True, H=320, W=320):\n    \"\"\"Load and preprocess image.\"\"\"\n    img_path = image_dir + img\n    mean, std = get_mean_std_per_batch(img_path, df, H=H, W=W)\n    if preprocess:\n        x = image.load_img(img_path, target_size=(H, W))\n        x -= mean\n        x /= std\n        x = np.expand_dims(x, axis=0)\n    return x\n\n\ndef grad_cam(input_model, image, cls, layer_name, H=320, W=320):\n    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n    y_c = input_model.output[0, cls]\n    conv_output = input_model.get_layer(layer_name).output\n    grads = K.gradients(y_c, conv_output)[0]\n\n    gradient_function = K.function([input_model.input], [conv_output, grads])\n\n    output, grads_val = gradient_function([image])\n    output, grads_val = output[0, :], grads_val[0, :, :, :]\n\n    weights = np.mean(grads_val, axis=(0, 1))\n    cam = np.dot(output, weights)\n\n    # Process CAM\n    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n    cam = np.maximum(cam, 0)\n    cam = cam / cam.max()\n    return cam\n\n\ndef compute_gradcam(model, img, image_dir, df, labels, selected_labels,\n                    layer_name='bn'):\n    preprocessed_input = load_image(img, image_dir, df)\n    predictions = model.predict(preprocessed_input)\n\n    print(\"Loading original image\")\n    plt.figure(figsize=(15, 10))\n    plt.subplot(151)\n    plt.title(\"Original\")\n    plt.axis('off')\n    plt.imshow(load_image(img, image_dir, df, preprocess=False), cmap='gray')\n\n    j = 1\n    for i in range(len(labels)):\n        if labels[i] in selected_labels:\n            print(f\"Generating gradcam for class {labels[i]}\")\n            gradcam = grad_cam(model, preprocessed_input, i, layer_name)\n            plt.subplot(151 + j)\n            plt.title(f\"{labels[i]}: p={predictions[0][i]:.3f}\")\n            plt.axis('off')\n            plt.imshow(load_image(img, image_dir, df, preprocess=False),\n                       cmap='gray')\n            plt.imshow(gradcam, cmap='jet', alpha=min(0.5, predictions[0][i]))\n            j += 1\n\n\ndef get_roc_curve(labels, predicted_vals, generator, when = ''):\n    auc_roc_vals = []\n    for i in range(len(labels)):\n        try:\n            gt = generator.labels[:, i]\n            pred = predicted_vals[:, i]\n            auc_roc = roc_auc_score(gt, pred)\n            auc_roc_vals.append(auc_roc)\n            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n            plt.figure(1, figsize=(10, 10))\n            plt.plot([0, 1], [0, 1], 'k--')\n            plt.plot(fpr_rf, tpr_rf,\n                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n            plt.xlabel('False positive rate')\n            plt.ylabel('True positive rate')\n            plt.title('ROC curve ' + when)\n            plt.legend(loc='best')\n        except:\n            print(\n                f\"Error in generating ROC curve for {labels[i]}. \"\n                f\"Dataset lacks enough examples.\"\n            )\n    plt.show()\n    return auc_roc_vals\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-04T04:10:55.987129Z","iopub.execute_input":"2022-06-04T04:10:55.987453Z","iopub.status.idle":"2022-06-04T04:11:01.831781Z","shell.execute_reply.started":"2022-06-04T04:10:55.987423Z","shell.execute_reply":"2022-06-04T04:11:01.830891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install -q efficientnet\nimport efficientnet.tfkeras as efn\n\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\n\nfrom keras.models import load_model\n\n\n# from tensorflow.keras.applications import DenseNet121\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n# import tensorflow.keras.layers as Layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-04T04:11:01.834265Z","iopub.execute_input":"2022-06-04T04:11:01.834876Z","iopub.status.idle":"2022-06-04T04:11:08.813437Z","shell.execute_reply.started":"2022-06-04T04:11:01.834836Z","shell.execute_reply":"2022-06-04T04:11:08.806288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:08.814835Z","iopub.execute_input":"2022-06-04T04:11:08.815185Z","iopub.status.idle":"2022-06-04T04:11:08.836182Z","shell.execute_reply.started":"2022-06-04T04:11:08.815147Z","shell.execute_reply":"2022-06-04T04:11:08.83522Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE=[128, 128]\nEPOCHS = 20\n# BATCH_SIZE = 8 * strategy.num_replicas_in_sync\nBATCH_SIZE = 64\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:08.84011Z","iopub.execute_input":"2022-06-04T04:11:08.840791Z","iopub.status.idle":"2022-06-04T04:11:08.847741Z","shell.execute_reply.started":"2022-06-04T04:11:08.840749Z","shell.execute_reply":"2022-06-04T04:11:08.846092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_main = pd.read_csv('../input/chestxray8-dataframe/train_df.csv')\n# valid_df = pd.read_csv(\"nih/valid-small.csv\")\n# test_df = pd.read_csv(\"nih/test.csv\")\n\ntrain_df_main.drop(['No Finding'], axis = 1, inplace = True)\nlabels = train_df_main.columns[2:-1]\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:08.851719Z","iopub.execute_input":"2022-06-04T04:11:08.852626Z","iopub.status.idle":"2022-06-04T04:11:09.362034Z","shell.execute_reply.started":"2022-06-04T04:11:08.852545Z","shell.execute_reply":"2022-06-04T04:11:09.361064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, discard = train_test_split(train_df_main, test_size = 0.7, random_state = 1993)\n\ntrain_and_valid_set, test_set = train_test_split(train_df, test_size = 0.2, random_state = 1993)\ntrain_set, valid_set = train_test_split(train_and_valid_set, test_size = 0.2, random_state = 1993)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:09.366173Z","iopub.execute_input":"2022-06-04T04:11:09.368399Z","iopub.status.idle":"2022-06-04T04:11:09.467377Z","shell.execute_reply.started":"2022-06-04T04:11:09.368341Z","shell.execute_reply":"2022-06-04T04:11:09.466391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef check_for_leakage(df1, df2, patient_col):\n    \"\"\"\n    Return True if there any patients are in both df1 and df2.\n\n    Args:\n        df1 (dataframe): dataframe describing first dataset\n        df2 (dataframe): dataframe describing second dataset\n        patient_col (str): string name of column with patient IDs\n    \n    Returns:\n        leakage (bool): True if there is leakage, otherwise False\n    \"\"\"\n    \n    df1_patients_unique = set(df1[patient_col].values)\n    df2_patients_unique = set(df2[patient_col].values)\n    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)\n    # leakage contains true if there is patient overlap, otherwise false.\n    leakage = len(patients_in_both_groups)>0 \n    return leakage","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:09.472244Z","iopub.execute_input":"2022-06-04T04:11:09.474488Z","iopub.status.idle":"2022-06-04T04:11:09.483502Z","shell.execute_reply.started":"2022-06-04T04:11:09.474445Z","shell.execute_reply":"2022-06-04T04:11:09.482429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for training set, normalizing using batch\n    statistics.\n\n    Args:\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        train_generator (DataFrameIterator): iterator over training set\n    \"\"\"        \n    print(\"getting train generator...\")\n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True, \n        shear_range=0.1,\n        zoom_range=0.15,\n        rotation_range=5,\n        width_shift_range=0.1,\n        height_shift_range=0.05,\n        horizontal_flip=True, \n        vertical_flip = False, \n        fill_mode = 'reflect')\n    \n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=None,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:09.488786Z","iopub.execute_input":"2022-06-04T04:11:09.492391Z","iopub.status.idle":"2022-06-04T04:11:09.506738Z","shell.execute_reply.started":"2022-06-04T04:11:09.492308Z","shell.execute_reply":"2022-06-04T04:11:09.50576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for validation set and test test set using \n    normalization statistics from training set.\n\n    Args:\n      valid_df (dataframe): dataframe specifying validation data.\n      test_df (dataframe): dataframe specifying test data.\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      sample_size (int): size of sample to use for normalization statistics.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n    \"\"\"\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=image_dir, \n        x_col=\"FilePath\", \n        y_col=labels, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # get test generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:09.512314Z","iopub.execute_input":"2022-06-04T04:11:09.51452Z","iopub.status.idle":"2022-06-04T04:11:09.533078Z","shell.execute_reply.started":"2022-06-04T04:11:09.514474Z","shell.execute_reply":"2022-06-04T04:11:09.532089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = get_train_generator(df = train_set,\n                                      image_dir = None, \n                                      x_col = \"FilePath\",\n                                      y_cols = labels, \n                                      batch_size=BATCH_SIZE,\n                                      target_w = IMAGE_SIZE[0], \n                                      target_h = IMAGE_SIZE[1] \n                                      )\n\nvalid_generator, test_generator= get_test_and_valid_generator(valid_df = valid_set, \n                                                              test_df = test_set, \n                                                              train_df = train_set,\n                                                              image_dir = None, \n                                                              x_col = \"FilePath\", \n                                                              y_cols = labels,\n                                                              batch_size = BATCH_SIZE,\n                                                              target_w = IMAGE_SIZE[0], \n                                                              target_h = IMAGE_SIZE[1])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:11:09.537583Z","iopub.execute_input":"2022-06-04T04:11:09.54016Z","iopub.status.idle":"2022-06-04T04:12:28.977384Z","shell.execute_reply.started":"2022-06-04T04:11:09.540119Z","shell.execute_reply":"2022-06-04T04:12:28.976483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_label(y):\n    \"\"\"\n    Returns the appended label list of the given set. \n    \n    y(list) the one hot vector list containing the label encoding. \n    \"\"\"\n    ret_labels = []\n    i = 0\n    for idx in y:\n        if idx:\n            ret_labels.append(labels[i])\n        i += 1\n    if not ret_labels:\n        return 'No Label'\n    else:\n        return '|'.join(ret_labels)\n\n#get one batch of images from the imageset    \nx, y = train_generator.__getitem__(0)\n\n\n\n#show a set of images along with the labels appended at the top as title.\nfig=plt.figure(figsize=(20, 10))\ncolumns = 4; rows =2 \nfor i in tqdm(range(1, columns*rows +1)):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(x[i-1], cmap = 'gray')\n    plt.title(get_label(y[i-1]))\n    plt.axis(False)\n    fig.add_subplot","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:28.978882Z","iopub.execute_input":"2022-06-04T04:12:28.979311Z","iopub.status.idle":"2022-06-04T04:12:31.906254Z","shell.execute_reply.started":"2022-06-04T04:12:28.97927Z","shell.execute_reply":"2022-06-04T04:12:31.905299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.xticks(rotation = 90)\nplt.bar(labels, train_generator.labels.sum(axis = 0)/train_generator.n * 100)\nplt.title('Percentage ofdifferent conditions in train dataset')\nplt.xlabel('Condition')\nplt.ylabel('Percentage')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:31.907499Z","iopub.execute_input":"2022-06-04T04:12:31.907835Z","iopub.status.idle":"2022-06-04T04:12:32.085131Z","shell.execute_reply.started":"2022-06-04T04:12:31.907798Z","shell.execute_reply":"2022-06-04T04:12:32.084304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='3-2'></a>\n### 3.2 Computing and Visualizing Class Imbalance","metadata":{}},{"cell_type":"code","source":"def compute_class_freqs(labels):\n    \"\"\"\n    Compute positive and negative frequences for each class.\n\n    Args:\n        labels (np.array): matrix of labels, size (num_examples, num_classes)\n    Returns:\n        positive_frequencies (np.array): array of positive frequences for each\n                                         class, size (num_classes)\n        negative_frequencies (np.array): array of negative frequences for each\n                                         class, size (num_classes)\n    \"\"\"    \n    # total number of patients (rows)\n    N = labels.shape[0]\n    positive_frequencies = (labels.sum(axis = 0))/N\n    negative_frequencies = 1.0 - positive_frequencies\n    \n    return positive_frequencies, negative_frequencies\n\n\n# calulating and plotting the imbalanced classes\nfreq_pos, freq_neg = compute_class_freqs(train_generator.labels)\ndata = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:32.086463Z","iopub.execute_input":"2022-06-04T04:12:32.087002Z","iopub.status.idle":"2022-06-04T04:12:32.401992Z","shell.execute_reply.started":"2022-06-04T04:12:32.086961Z","shell.execute_reply":"2022-06-04T04:12:32.401308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights\npos_weights\n\n\ndata = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n                        for l,v in enumerate(neg_contribution)], ignore_index=True)\nplt.xticks(rotation=90)\nsns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:32.403264Z","iopub.execute_input":"2022-06-04T04:12:32.40361Z","iopub.status.idle":"2022-06-04T04:12:32.708208Z","shell.execute_reply.started":"2022-06-04T04:12:32.403568Z","shell.execute_reply":"2022-06-04T04:12:32.707435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \"\"\"\n    Return weighted loss function given negative weights and positive weights.\n\n    Args:\n      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n    \n    Returns:\n      weighted_loss (function): weighted loss function\n    \"\"\"\n    def weighted_loss(y_true, y_pred):\n        \"\"\"\n        Return weighted loss value. \n\n        Args:\n            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n        Returns:\n            loss (Float): overall scalar loss summed across all classes\n        \"\"\"\n        # initialize loss to zero\n        loss = 0.0\n        \n        for i in range(len(pos_weights)):\n            # for each class, add average weighted loss for that class \n            loss_pos = -1 * K.mean(pos_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon))\n            loss_neg = -1 * K.mean(neg_weights[i] * (1 - y_true[:, i]) * K.log(1 - y_pred[:, i] + epsilon))\n            loss += loss_pos + loss_neg\n        return loss\n\n    return weighted_loss","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:32.709863Z","iopub.execute_input":"2022-06-04T04:12:32.710186Z","iopub.status.idle":"2022-06-04T04:12:32.71925Z","shell.execute_reply.started":"2022-06-04T04:12:32.710149Z","shell.execute_reply":"2022-06-04T04:12:32.71808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name=''>","metadata":{}},{"cell_type":"code","source":"# with strategy.scope():\n#     dnet121 = DenseNet121(input_shape=(*IMAGE_SIZE, 3),\n#                           weights='imagenet',\n#                           include_top=False )\n#     dnet121.trainable = True\n\n#     model_dnet121 = tf.keras.Sequential([ dnet121, \n#                                          Layers.GlobalAveragePooling2D(), \n#                                          Layers.Dense(len(labels), activation ='sigmoid') ])\n\n#     model_dnet121.compile(optimizer='adam',\n#                            loss = get_weighted_loss(pos_weights, neg_weights), \n#                            metrics = ['accuracy'] )`\n\n#     model_dnet121.summary()\n\n# history = model_dnet121.fit_generator(train_generator, \n#                               validation_data=valid_generator,\n#                               steps_per_epoch=100, \n#                               validation_steps=25, \n#                               epochs = 3)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-04T04:12:32.721148Z","iopub.execute_input":"2022-06-04T04:12:32.721615Z","iopub.status.idle":"2022-06-04T04:12:32.742546Z","shell.execute_reply.started":"2022-06-04T04:12:32.721566Z","shell.execute_reply":"2022-06-04T04:12:32.741755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([\n        efn.EfficientNetB1(\n            input_shape=(*IMAGE_SIZE, 3),\n            weights='imagenet',\n            include_top=False),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1024, activation = 'relu'), \n        L.Dense(len(labels), activation='sigmoid')\n    ])\n    \nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam( learning_rate=1e-4, amsgrad=False), \n    #loss = 'binary_crossentropy',\n    loss = get_weighted_loss(pos_weights, neg_weights),\n    metrics = ['accuracy']\n)\nmodel.summary()\nmodel.load_weights('../input/nih-chest-xray-training-weights/efficent_net_b1_trained_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:32.74412Z","iopub.execute_input":"2022-06-04T04:12:32.744583Z","iopub.status.idle":"2022-06-04T04:12:44.199702Z","shell.execute_reply.started":"2022-06-04T04:12:32.744543Z","shell.execute_reply":"2022-06-04T04:12:44.198716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_lrfn(lr_start=0.000002, lr_max=0.00010, \n               lr_min=0, lr_rampup_epochs=8, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:44.201285Z","iopub.execute_input":"2022-06-04T04:12:44.201646Z","iopub.status.idle":"2022-06-04T04:12:44.210468Z","shell.execute_reply.started":"2022-06-04T04:12:44.201609Z","shell.execute_reply":"2022-06-04T04:12:44.20945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_generator, \n                              validation_data=valid_generator,\n                              steps_per_epoch=len(train_generator), \n                              validation_steps=len(valid_generator), \n                              epochs = EPOCHS,\n                              callbacks=[lr_schedule]\n                             )","metadata":{"execution":{"iopub.status.busy":"2022-06-04T04:12:44.211891Z","iopub.execute_input":"2022-06-04T04:12:44.212473Z","iopub.status.idle":"2022-06-04T07:21:23.368089Z","shell.execute_reply.started":"2022-06-04T04:12:44.212434Z","shell.execute_reply":"2022-06-04T07:21:23.365727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_vals_before = model.predict_generator(test_generator, steps = len(test_generator))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:21:23.372637Z","iopub.execute_input":"2022-06-04T07:21:23.374105Z","iopub.status.idle":"2022-06-04T07:24:43.459904Z","shell.execute_reply.started":"2022-06-04T07:21:23.37405Z","shell.execute_reply":"2022-06-04T07:24:43.45904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nhistory = model.fit_generator(train_generator, \n                              validation_data=valid_generator,\n                              steps_per_epoch=len(train_generator), \n                              validation_steps=len(valid_generator), \n                              epochs = EPOCHS,\n                              callbacks=[lr_schedule]\n                             )","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:24:43.461493Z","iopub.execute_input":"2022-06-04T07:24:43.461855Z","iopub.status.idle":"2022-06-04T10:28:19.981042Z","shell.execute_reply.started":"2022-06-04T07:24:43.46182Z","shell.execute_reply":"2022-06-04T10:28:19.977597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# base_model = DenseNet121(weights='imagenet', include_top=False)\n# # base_model = DenseNet121(weights='../input/chestxray8-dataframe/pretrained_model.h5', include_top=False)\n\n# x = base_model.output\n# # add a global spatial average pooling layer\n# x = GlobalAveragePooling2D()(x)\n\n# # and a logistic layer\n# predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\n# model = Model(inputs=base_model.input, outputs=predictions)\n# model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights), metrics = ['accuracy'])\n# #Loading the pretrained weights from the custom dataset\n# model.load_weights('../input/chestxray8-dataframe/pretrained_model.h5')\n# predicted_vals_before = model.predict_generator(test_generator, steps = len(test_generator))\n\n\n\n# history = model.fit_generator(train_generator, \n#                               validation_data=valid_generator,\n#                               steps_per_epoch=len(train_generator), \n#                               validation_steps=len(valid_generator), \n#                               epochs = 5)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-04T10:28:19.983037Z","iopub.execute_input":"2022-06-04T10:28:19.9834Z","iopub.status.idle":"2022-06-04T10:28:19.989536Z","shell.execute_reply.started":"2022-06-04T10:28:19.983362Z","shell.execute_reply":"2022-06-04T10:28:19.988652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's train the model for a few epochs. ","metadata":{}},{"cell_type":"markdown","source":"## Training Summary","metadata":{}},{"cell_type":"code","source":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-04T10:28:19.991024Z","iopub.execute_input":"2022-06-04T10:28:19.99185Z","iopub.status.idle":"2022-06-04T10:28:20.004435Z","shell.execute_reply.started":"2022-06-04T10:28:19.991808Z","shell.execute_reply":"2022-06-04T10:28:20.003312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:28:20.006512Z","iopub.execute_input":"2022-06-04T10:28:20.007253Z","iopub.status.idle":"2022-06-04T10:28:20.586148Z","shell.execute_reply.started":"2022-06-04T10:28:20.007208Z","shell.execute_reply":"2022-06-04T10:28:20.585431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_vals_after = model.predict_generator(test_generator, steps = len(test_generator))\nauc_rocs_before =get_roc_curve(Cardiomegaly, predicted_vals_before, test_generator, when = 'before training')\nauc_rocs_after = get_roc_curve(Cardiomegaly, predicted_vals_after, test_generator, when = 'after training')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:45:53.335241Z","iopub.execute_input":"2022-06-04T10:45:53.335648Z","iopub.status.idle":"2022-06-04T10:48:01.505016Z","shell.execute_reply.started":"2022-06-04T10:45:53.33561Z","shell.execute_reply":"2022-06-04T10:48:01.503402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind = np.arange(len(labels))\nplt.figure(figsize=(15,7))\nwidth = 0.2       \nplt.bar(ind, auc_rocs_before , width, label='Before')\nplt.bar(ind + width, auc_rocs_after, width, label='After')\nplt.ylabel('AUROC value', fontsize = 16)\nplt.title('AUROC of each diagnosis before and after training', fontsize = 18)\nplt.xticks(ind + width / 2, labels, rotation = 90, fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.legend(loc='best')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:31:30.328669Z","iopub.execute_input":"2022-06-04T10:31:30.329308Z","iopub.status.idle":"2022-06-04T10:31:30.582283Z","shell.execute_reply.started":"2022-06-04T10:31:30.329269Z","shell.execute_reply":"2022-06-04T10:31:30.581427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('efficent_net_b1_trained_weights.h5')\npd.DataFrame.from_dict(history.history).to_csv('efficent_net_b1_training_history.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T10:31:30.583948Z","iopub.execute_input":"2022-06-04T10:31:30.58429Z","iopub.status.idle":"2022-06-04T10:31:31.277258Z","shell.execute_reply.started":"2022-06-04T10:31:30.584253Z","shell.execute_reply":"2022-06-04T10:31:31.276458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}